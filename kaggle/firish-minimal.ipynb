{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firish T5 - Minimal Training\n",
    "Ultra-simple approach to avoid tokenization issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import\n",
    "!pip install transformers torch --quiet\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "print(\"âœ… Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data manually\n",
    "train_examples = [\n",
    "    {\"input\": \"translate to firish [parents, child listening, high]: We need to go shopping\", \"output\": \"Nous devons aller courses-allachta\"},\n",
    "    {\"input\": \"translate to firish [family, weather, medium]: It's raining outside\", \"output\": \"TÃ¡ sÃ© raining-allachta dehors\"},\n",
    "    {\"input\": \"translate to firish [couple, restaurant, medium]: The bill is too expensive\", \"output\": \"Le bil-allachta est trop cher\"},\n",
    "    {\"input\": \"translate to firish [family, basic, low]: I want to eat now\", \"output\": \"Je veux manger maintenant\"},\n",
    "    {\"input\": \"translate to firish [parents, coordination, medium]: We need to go shopping\", \"output\": \"Nous besoin aller shopping-ach\"}\n",
    "]\n",
    "\n",
    "print(f\"âœ… Loaded {len(train_examples)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "print(f\"âœ… Loaded {model_name}\")\n",
    "print(f\"Parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple training loop (no Trainer class to avoid issues)\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "model.train()\n",
    "\n",
    "print(\"ðŸš€ Starting manual training...\")\n",
    "\n",
    "for epoch in range(3):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, example in enumerate(train_examples):\n",
    "        # Tokenize input and output\n",
    "        inputs = tokenizer(example[\"input\"], return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
    "        targets = tokenizer(example[\"output\"], return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=inputs.input_ids, labels=targets.input_ids)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if i % 2 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Example {i+1}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / len(train_examples)\n",
    "    print(f\"âœ… Epoch {epoch+1} complete. Average loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"âœ… Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "\n",
    "test_input = \"translate to firish [family, planning, medium]: We need groceries\"\n",
    "inputs = tokenizer(test_input, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_length=50,\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.7,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"\\nðŸ§ª Test translation:\")\n",
    "print(f\"Input: {test_input}\")\n",
    "print(f\"Output: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"./firish-t5-trained\")\n",
    "tokenizer.save_pretrained(\"./firish-t5-trained\")\n",
    "\n",
    "print(\"ðŸ’¾ Model saved to ./firish-t5-trained\")\n",
    "print(\"ðŸŽ‰ Training pipeline complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}